from pyspark.sql import SparkSession
from pyspark.sql.functions import when, col

# Initialize Spark session
spark = SparkSession.builder.appName("MusicDataAnalysis").getOrCreate()

# File path
file_path = "/home/cloudera/music_tracks.csv"

# 1. Data Loading and Schema Understanding
music_df = spark.read.csv(file_path, header=True, inferSchema=True)
print("Schema of the dataset:")
music_df.printSchema()

print("Sample data:")
music_df.show(5)

# 2. Data Aggregation
# Calculate average danceability, energy, and tempo by artist
agg_df = music_df.groupBy("artist_name").agg(
    {"danceability": "avg", "energy": "avg", "tempo": "avg"}
).withColumnRenamed("avg(danceability)", "avg_danceability") \
 .withColumnRenamed("avg(energy)", "avg_energy") \
 .withColumnRenamed("avg(tempo)", "avg_tempo")

print("Average metrics by artist:")
agg_df.show()

# Find top 5 artists with the highest average popularity
top_artists = music_df.groupBy("artist_name").agg({"popularity": "avg"}) \
    .withColumnRenamed("avg(popularity)", "avg_popularity") \
    .orderBy("avg_popularity", ascending=False).limit(5)

print("Top 5 artists by popularity:")
top_artists.show()

# 3. Data Transformation
# Add energy_level column
transformed_df = music_df.withColumn(
    "energy_level",
    when(col("energy") > 0.8, "High Energy").otherwise("Regular Energy")
)

print("Data with energy_level classification:")
transformed_df.show()

# Group by energy_level and calculate average popularity and loudness
energy_agg_df = transformed_df.groupBy("energy_level").agg(
    {"popularity": "avg", "loudness": "avg"}
).withColumnRenamed("avg(popularity)", "avg_popularity") \
 .withColumnRenamed("avg(loudness)", "avg_loudness")

print("Average metrics by energy level:")
energy_agg_df.show()

# 4. Data Exporting
# Filter and export High Energy data
high_energy_df = transformed_df.filter(col("energy_level") == "High Energy")
output_path = "/home/cloudera/high_energy_tracks.csv"

high_energy_df.write.csv(output_path, header=True)
print(f"High energy data exported to: {output_path}")

# Stop Spark session
spark.stop()
